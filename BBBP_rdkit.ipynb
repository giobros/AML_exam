{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c983478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import set_printoptions\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression                         \n",
    "from sklearn.tree import DecisionTreeClassifier                             \n",
    "from sklearn.neighbors import KNeighborsClassifier                          \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis        \n",
    "from sklearn.naive_bayes import GaussianNB                                  \n",
    "from sklearn.svm import SVC    \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5c213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rdkit = pd.read_csv(\"./BBBP_rdkit_descriptors.csv\") \n",
    "print(df_rdkit.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f62227b",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = df_rdkit.describe()\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deca93f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_rdkit.drop(columns=['name'], errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08a476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation-based feature reduction\n",
    "corr = df_cleaned.corr()\n",
    "upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "df_uncorrelated = df_cleaned.drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096be41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing features with low variance: \n",
    "X_all =  df_uncorrelated.drop(columns=['p_np'])\n",
    "Y_all =  df_uncorrelated['p_np']\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "sel.fit_transform(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fed676",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Univariate feature selection: this selects features most strongly related to the target (based on F-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a342177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import pandas as pd\n",
    "\n",
    "# Select top k features using ANOVA F-test\n",
    "k = 30  # or any number of top features you want\n",
    "selector = SelectKBest(score_func=f_classif, k=k)\n",
    "X_new = selector.fit_transform(X_all, Y_all)\n",
    "\n",
    "# Get selected feature names\n",
    "mask = selector.get_support()  # boolean mask of selected features\n",
    "selected_features = X_all.columns[mask]\n",
    "\n",
    "# Show selected features and their F-scores\n",
    "scores = selector.scores_[mask]\n",
    "feature_scores = pd.Series(scores, index=selected_features).sort_values(ascending=False)\n",
    "print(\" Top features selected using ANOVA F-test:\\n\")\n",
    "print(feature_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97243ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selected_features_30 = [\n",
    "    \"TPSA\", \"NHOHCount\", \"PEOE_VSA10\", \"PEOE_VSA1\", \"qed\", \"fr_lactam\", \"SMR_VSA2\", \"EState_VSA8\", \"SlogP_VSA2\",\n",
    "    \"VSA_EState2\", \"NumRotatableBonds\", \"MolWt\", \"SlogP_VSA3\", \"PEOE_VSA13\", \"fr_sulfide\", \"fr_Al_COO\",\n",
    "    \"VSA_EState3\", \"MolLogP\", \"Phi\", \"PEOE_VSA12\", \"NumAtomStereoCenters\", \"EState_VSA10\", \"fr_Al_OH\",\n",
    "    \"HallKierAlpha\", \"fr_Ar_OH\", \"PEOE_VSA9\", \"PEOE_VSA5\", \"NumSaturatedHeterocycles\", \"SMR_VSA10\", \"PEOE_VSA2\"\n",
    "]\n",
    "\n",
    "# Create a new dataset with just these features + target\n",
    "selected_df = df_cleaned[selected_features_30 + ['p_np']].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed7f421",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "array = selected_df.values\n",
    "X = selected_df.drop(columns=['p_np'])\n",
    "y = selected_df['p_np']\n",
    "\n",
    "corr_matrix = X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026ea71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 20))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True, linewidths=0.5)\n",
    "plt.title(\"Correlation Matrix of Top 20 Features\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed18c0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_all =  df_uncorrelated.drop(columns=['p_np'])\n",
    "Y_all =  df_uncorrelated['p_np']\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02209d1a",
   "metadata": {},
   "source": [
    " BENCHMARK COMPARISON\\\n",
    " Benchmark comparison of multiple machine learning models using cross-validation, and evaluating them based on ROC-AUC and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd634b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prepare models\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='lbfgs', max_iter=500)))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(probability=True)))  # Important: probability=True for SVC\n",
    "\n",
    "# evaluate each model\n",
    "roc_results = []\n",
    "f1_results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=7, shuffle=True)\n",
    "\n",
    "    # ROC-AUC\n",
    "    cv_roc = cross_val_score(model, X_scaled, Y_all, cv=kfold, scoring='roc_auc')\n",
    "    roc_results.append(cv_roc)\n",
    "\n",
    "    # F1-Score\n",
    "    cv_f1 = cross_val_score(model, X_scaled, Y_all, cv=kfold, scoring='f1')\n",
    "    f1_results.append(cv_f1)\n",
    "\n",
    "    names.append(name)\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  ROC-AUC Mean: {cv_roc.mean():.3f} (Std: {cv_roc.std():.3f})\")\n",
    "    print(f\"  F1-Score Mean: {cv_f1.mean():.3f} (Std: {cv_f1.std():.3f})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4154e89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot algorithm comparison\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Algorithms comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(roc_results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8cac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "fig.suptitle('Algorithms Comparison - F1 Scores')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(f1_results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.ylabel('F1 Score')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85023875",
   "metadata": {},
   "source": [
    "IMBALANCED CLASSIFICATION\\\n",
    "Imbalanced classification strategy comparison for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f706c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(\n",
    "    X_scaled, Y_all, test_size=0.2, stratify=Y_all, random_state=42\n",
    ")\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# ----- 1. Logistic Regression with class_weight=none -----\n",
    "# On imbalanced datasets, it tends to favor the majority class.\n",
    "\n",
    "model_none = LogisticRegression(solver='lbfgs', max_iter=300, class_weight=None)\n",
    "\n",
    "y_pred_none= cross_val_predict(model_none, X_scaled, Y_all, cv=cv)\n",
    "y_prob_none = cross_val_predict(model_none, X_scaled, Y_all, cv=cv, method='predict_proba')[:, 1]\n",
    "\n",
    "acc_n = accuracy_score(Y_all, y_pred_none)\n",
    "roc_n = roc_auc_score(Y_all, y_prob_none)\n",
    "print(\" LogisticRegression with class_weight='balanced'\")\n",
    "print(\"Accuracy:\", round(acc_n, 3))\n",
    "print(\"ROC-AUC:\", round(roc_n, 3))\n",
    "print(\"Classification Report:\\n\", classification_report(Y_all, y_pred_none))\n",
    "\n",
    "# ----- 2. Logistic Regression with class_weight='balanced' -----\n",
    "#  The “balanced” mode uses the values of y to automatically adjust weights \n",
    "#  inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y)).\n",
    "\n",
    "\n",
    "model_weighted = LogisticRegression(solver='lbfgs', max_iter=300, class_weight='balanced')\n",
    "\n",
    "y_pred_weighted = cross_val_predict(model_weighted, X_scaled, Y_all, cv=cv)\n",
    "y_prob_weighted = cross_val_predict(model_weighted, X_scaled, Y_all, cv=cv, method='predict_proba')[:, 1]\n",
    "\n",
    "acc_w = accuracy_score(Y_all, y_pred_weighted)\n",
    "roc_w = roc_auc_score(Y_all, y_prob_weighted)\n",
    "print(\" LogisticRegression with class_weight='balanced'\")\n",
    "print(\"Accuracy:\", round(acc_w, 3))\n",
    "print(\"ROC-AUC:\", round(roc_w, 3))\n",
    "print(\"Classification Report:\\n\", classification_report(Y_all, y_pred_weighted))\n",
    "\n",
    "\n",
    "# ----- 3. SMOTE + Logistic Regression -----\n",
    "# Applies SMOTE within cross-validation folds to generate synthetic minority samples: DOI: https://doi.org/10.1613/jair.953\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "model_smote = LogisticRegression(solver='lbfgs', max_iter=300)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('smote', smote),\n",
    "    ('logreg', model_smote)\n",
    "])\n",
    "\n",
    "y_pred_smote = cross_val_predict(pipeline, X_scaled, Y_all, cv=cv)\n",
    "y_prob_smote = cross_val_predict(pipeline, X_scaled, Y_all, cv=cv, method='predict_proba')[:, 1]\n",
    "\n",
    "acc_s = accuracy_score(Y_all, y_pred_smote)\n",
    "roc_s = roc_auc_score(Y_all, y_prob_smote)\n",
    "print(\"\\n LogisticRegression with SMOTE\")\n",
    "print(\"Accuracy:\", round(acc_s, 3))\n",
    "print(\"ROC-AUC:\", round(roc_s, 3))\n",
    "print(\"Classification Report:\\n\", classification_report(Y_all, y_pred_smote))\n",
    "\n",
    "\n",
    "# ----- Confusion Matrices -----\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 4))  \n",
    "\n",
    "cm_none = confusion_matrix(Y_all, y_pred_none)\n",
    "sns.heatmap(cm_none, annot=True, fmt='d', cmap='Reds', ax=axs[0])\n",
    "axs[0].set_title(\"Confusion Matrix\\nclass_weight=None\")\n",
    "axs[0].set_xlabel(\"Predicted\")\n",
    "axs[0].set_ylabel(\"Actual\")\n",
    "\n",
    "\n",
    "cm_weighted = confusion_matrix(Y_all, y_pred_weighted)\n",
    "sns.heatmap(cm_weighted, annot=True, fmt='d', cmap='Blues', ax=axs[1])\n",
    "axs[1].set_title(\"Confusion Matrix\\nclass_weight='balanced'\")\n",
    "axs[1].set_xlabel(\"Predicted\")\n",
    "axs[1].set_ylabel(\"Actual\")\n",
    "\n",
    "cm_smote = confusion_matrix(Y_all, y_pred_smote)\n",
    "sns.heatmap(cm_smote, annot=True, fmt='d', cmap='Greens', ax=axs[2])\n",
    "axs[2].set_title(\"Confusion Matrix\\nSMOTE + LogisticRegression\")\n",
    "axs[2].set_xlabel(\"Predicted\")\n",
    "axs[2].set_ylabel(\"Actual\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aea933d",
   "metadata": {},
   "source": [
    "From the plot we can see clearly that without balancing we have:\\\n",
    "High FN: model is misclassifying many BBB− as BBB+ \\\n",
    "Low TN:  model rarely predicts class 0 correctly \\\n",
    "High TP:  model may be blindly favoring class 1\\\n",
    "\n",
    "Using class_weight='balanced\\\n",
    "Forces the model to pay attention to both classes, even when one is smaller.\n",
    "\n",
    "Using SMOTE:\\\n",
    "Creates synthetic examples of the minority class (class 0) during training. Gives the model more balanced data to learn from in each fold.\n",
    "\n",
    "Unbalanced model biases heavily toward class 1 and ignores class 0. had high recall for class 1 but terrible performance on class 0 (missed many non-penetrants).\\\n",
    "Balanced and SMOTE models give more useful, realistic results — with much better treatment of non-penetrant compounds (class 0).\\\n",
    "Balanced and SMOTE:\\\n",
    "Correctly identified more class 0 compounds.\n",
    "Gave lower but more reliable accuracy.\n",
    "Produced better confusion matrices (more TNs, fewer FNs for class 0).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0354b244",
   "metadata": {},
   "source": [
    "Compares 3 versions of SVM on BBBP:\n",
    "Untuned SVM (default params)\n",
    "\n",
    "SVM tuned with GridSearchCV\n",
    "\n",
    "SVM tuned with Genetic Algorithm\n",
    "\n",
    "And for each version:\n",
    "\n",
    "Trains the model\n",
    "\n",
    "Evaluates with classification_report and ROC AUC\n",
    "\n",
    "Records and plots training time and ROC AUC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9656282",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "\n",
    "\n",
    "# ===========================\n",
    "#  Comparison Configuration\n",
    "# ===========================\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "# Track results\n",
    "results = {}\n",
    "\n",
    "# ===============================\n",
    "# 1. Untuned SVM\n",
    "# ===============================\n",
    "start = time.time()\n",
    "svm_untuned = SVC(probability=True, random_state=42)\n",
    "svm_untuned.fit(X_train_scaled, y_train)\n",
    "y_pred = svm_untuned.predict(X_test_scaled)\n",
    "y_prob = svm_untuned.predict_proba(X_test_scaled)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "end = time.time()\n",
    "\n",
    "results[\"Untuned\"] = {\n",
    "    \"auc\": auc,\n",
    "    \"time\": end - start,\n",
    "    \"report\": classification_report(y_test, y_pred)\n",
    "}\n",
    "print(\"\\n Untuned SVM\")\n",
    "print(results[\"Untuned\"][\"report\"])\n",
    "print(\"ROC AUC:\", auc)\n",
    "\n",
    "# ===============================\n",
    "# 2. GridSearchCV\n",
    "# ===============================\n",
    "start = time.time()\n",
    "grid = GridSearchCV(SVC(probability=True, random_state=42), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "best_svm_grid = grid.best_estimator_\n",
    "y_pred = best_svm_grid.predict(X_test_scaled)\n",
    "y_prob = best_svm_grid.predict_proba(X_test_scaled)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "end = time.time()\n",
    "\n",
    "results[\"GridSearchCV\"] = {\n",
    "    \"auc\": auc,\n",
    "    \"time\": end - start,\n",
    "    \"report\": classification_report(y_test, y_pred),\n",
    "    \"best_params\": grid.best_params_\n",
    "}\n",
    "print(\"\\n SVM with GridSearchCV\")\n",
    "print(results[\"GridSearchCV\"][\"report\"])\n",
    "print(\"ROC AUC:\", auc)\n",
    "print(\"Best Params:\", grid.best_params_)\n",
    "\n",
    "# ===============================\n",
    "# 3. Genetic Algorithm\n",
    "# ===============================\n",
    "def generate_population(size):\n",
    "    random.seed(42)\n",
    "\n",
    "    return [\n",
    "        {\n",
    "            'C': random.choice(param_grid['C']),\n",
    "            'gamma': random.choice(param_grid['gamma']),\n",
    "            'kernel': 'rbf'\n",
    "        }\n",
    "        for _ in range(size)\n",
    "    ]\n",
    "\n",
    "def fitness(ind):\n",
    "    model = SVC(**ind, probability=True, random_state=42)\n",
    "    scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='roc_auc')\n",
    "    return scores.mean()\n",
    "def crossover(p1, p2):\n",
    "    return {\n",
    "        'C': random.choice([p1['C'], p2['C']]),\n",
    "        'gamma': random.choice([p1['gamma'], p2['gamma']]),\n",
    "        'kernel': 'rbf'\n",
    "    }\n",
    "\n",
    "def mutate(ind, mutation_rate=0.1):\n",
    "    if random.random() < mutation_rate:\n",
    "        ind['C'] = random.choice(param_grid['C'])\n",
    "    if random.random() < mutation_rate:\n",
    "        ind['gamma'] = random.choice(param_grid['gamma'])\n",
    "    return ind\n",
    "\n",
    "def run_genetic_algorithm(pop_size=10, generations=5):\n",
    "    population = generate_population(pop_size)\n",
    "    best_scores = []\n",
    "\n",
    "    for gen in range(generations):\n",
    "        scored = [(ind, fitness(ind)) for ind in population]\n",
    "        scored.sort(key=lambda x: x[1], reverse=True)\n",
    "        elites = [x[0] for x in scored[:pop_size // 2]]\n",
    "        best_scores.append(scored[0][1])\n",
    "        offspring = [mutate(crossover(*random.sample(elites, 2))) for _ in range(pop_size // 2)]\n",
    "        population = elites + offspring\n",
    "\n",
    "    best_params = max([(ind, fitness(ind)) for ind in population], key=lambda x: x[1])[0]\n",
    "\n",
    "\n",
    "\n",
    "    return best_params\n",
    "\n",
    "start = time.time()\n",
    "best_params_ga = run_genetic_algorithm()\n",
    "svm_ga = SVC(**best_params_ga, probability=True, random_state=42)\n",
    "svm_ga.fit(X_train_scaled, y_train)\n",
    "y_pred = svm_ga.predict(X_test_scaled)\n",
    "y_prob = svm_ga.predict_proba(X_test_scaled)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "end = time.time()\n",
    "\n",
    "results[\"Genetic Algorithm\"] = {\n",
    "    \"auc\": auc,\n",
    "    \"time\": end - start,\n",
    "    \"report\": classification_report(y_test, y_pred),\n",
    "    \"best_params\": best_params_ga\n",
    "}\n",
    "print(\"\\n SVM with Genetic Algorithm\")\n",
    "print(results[\"Genetic Algorithm\"][\"report\"])\n",
    "print(\"ROC AUC:\", auc)\n",
    "print(\"Best Params:\", best_params_ga)\n",
    "\n",
    "# ===============================\n",
    "# Final Comparison Plot\n",
    "# ===============================\n",
    "labels = list(results.keys())\n",
    "auc_scores = [results[k][\"auc\"] for k in labels]\n",
    "times = [results[k][\"time\"] for k in labels]\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "ax1.bar(labels, auc_scores, color='skyblue', label='ROC AUC')\n",
    "ax1.set_ylabel('ROC AUC')\n",
    "ax1.set_ylim(0.5, 1.0)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(labels, times, color='red', marker='o', label='Time (s)')\n",
    "ax2.set_ylabel('Time (s)', color='red')\n",
    "\n",
    "plt.title(\"SVM Comparison: Untuned vs GridSearchCV vs GA\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4de5b8",
   "metadata": {},
   "source": [
    "The ROC AUC scores for all three models are very close, around 0.93 to 0.94.\\\n",
    "This means all three models—Untuned SVM, GridSearchCV, and Genetic Algorithm (GA)—perform similarly well in distinguishing between the two classes.\\\n",
    "The small differences in AUC are visually hard to distinguish due to the narrow range (0.93–0.94), but numerically they may still matter depending on the application\\\n",
    "Time increases dramatically from Untuned (~2s) to GridSearchCV (~4s) and jumps significantly for GA (~78s).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AML_exa_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
